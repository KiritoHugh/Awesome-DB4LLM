# Awesome-DB4LLM


## Inference system
- [	SOSP 2023 ] Efficient Memory Management for Large Language Model Serving with PagedAttention (vllm)
  [[paper]](https://arxiv.org/abs/2309.06180) [[project]](https://github.com/vllm-project/vllm)
- [	ICML 2023 ] FlexGen: High-throughput Generative Inference of Large Language Models with a Single GPU
  [[paper]](https://arxiv.org/abs/2303.06865) [[project]](https://github.com/FMInference/FlexGen)
